{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验说明\n",
    "\n",
    "## 作业说明\n",
    "\n",
    "### 目标：\n",
    "\n",
    "训练一个玩数独的神经网络，并得到较高的准确率\n",
    "\n",
    "### 背景：\n",
    "\n",
    "数独是一种经典的逻辑游戏，玩家需要根据9×9盘面上的已知数字，推理出所有剩余空格的数字，并满足每一行、每一列、每一个粗线宫（3x3）内的数字均含数字1～9，不重复。本教程展示如何训练一个用于产生数独游戏解的神经网络模型，并评估其准确率和计算时间。该模型得到9x9每个位置上填入数字1～9的概率分布（共有9x9x9个概率）。\n",
    "\n",
    "**训练过程**：将模型输出的概率分布与 ground truth 得到交叉熵 loss，并反向传播更新梯度。\n",
    "\n",
    "**推理过程**：我们**逐个地**填入数字，过程为先选中某个位置，再选择1～9的一个数字进行填入。\n",
    "循环执行以下操作，直到全部填充完毕：\n",
    "\n",
    "1. 将 1x9x9 的数独游戏输入模型，输出 81x9 的概率分布\n",
    "\n",
    "2. 每个位置如果需要填入，一定会选择数字1～9中概率最大的填入。即：\n",
    "\n",
    "$num_{x,y} = argmax(P_{x,y,1},P_{x,y,2},\\cdots,P_{x,y,9})$\n",
    "\n",
    "3. 每次需要选择一个空位置进行填入，我们选择所有空位置 $(x,y)$ 中 $P_{x,y}$ 最大的填入。\n",
    "\n",
    "$P_{x,y} = max(P_{x,y,1},P_{x,y,2},\\cdots,P_{x,y,9}) $\n",
    "\n",
    "$chosenP = argmax(P_{x,y})$\n",
    "\n",
    "### 任务：\n",
    "\n",
    "#### Q1： 训练模型\n",
    "\n",
    "运行baseline，训练和评估模型，并记录平均损失。你可以使用自己的数独游戏，输出结果，以判断模型是否可以得到合理的结果。\n",
    "\n",
    "由于数独可能存在多个合理解，因此只比较和 ground truth 的差别，并非是好的评估方式。请修改模型评估的代码，判断解是否合理，并计算模型得到合理解的概率。**请于q1.diff提交你的代码。**\n",
    "\n",
    "#### Q2： 尝试数据增广\n",
    "\n",
    "数独游戏可以尝试多种数据增广：左右翻转，上下翻转，旋转后性质不变；将1～9数字重新排列（shuffle）后，性质也不变。使用更小的样本（例如仅使用1000个训练数据），并修改代码，尝试使用更多的增广方式进行训练，得到Q1中的准确率尽可能高的模型。**请于q2.diff提交你的代码。**\n",
    "\n",
    "#### Q3： 训练一个量化神经网络\n",
    "\n",
    "从 baseline 模型中，提取量化神经网络。可以参考本文以了解量化的工作原理：[DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients](https://arxiv.org/abs/1606.06160)。\n",
    "\n",
    "建议分别将量化权重和特征的位数设置为2和1，你也可以使用其他配置。你可以使用 ground truth 进行训练，也可以采用知识蒸馏的方式，尝试获得更好的效果。详见：[知识蒸馏教程](https://studio.brainpp.com/project/4719)。\n",
    "\n",
    "完成以上任务，得到Q1中的准确率尽可能高的量化模型。 **请于q3.diff提交你的代码。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "\n",
    "来源：[1 million Sudoku games](https://www.kaggle.com/bryanpark/sudoku)，该数独数据集包含100万对9x9网格下的数独游戏以及解，存储于`./dataset/dataset-2115/sudoku.csv`。\n",
    "\n",
    "## 文件存储\n",
    "实验中生成的文件可以存储于 workspace 目录中。 查看工作区文件，该目录下的变更将会持久保存。 您的所有项目将共享一个存储空间，请及时清理不必要的文件，避免加载过慢。\n",
    "\n",
    "## 实验步骤\n",
    "\n",
    "1.导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import megengine as mge\n",
    "import megengine.module as M\n",
    "import megengine.functional as F\n",
    "import megengine.data.transform as T\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from megengine import tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from megengine.data import DataLoader, RandomSampler\n",
    "from megengine.data.dataset import Dataset\n",
    "from megengine.tensor import Parameter\n",
    "from megengine.optimizer import Adam\n",
    "from megengine.autodiff import GradManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.设计模型结构，并实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "class Net(M.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv0 = M.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu0 = M.ReLU()\n",
    "        self.bn0 = M.BatchNorm2d(64)\n",
    "        self.conv1 = M.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = M.ReLU()\n",
    "        self.bn1 = M.BatchNorm2d(64)\n",
    "        self.conv2 = M.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = M.ReLU()\n",
    "        self.bn2 = M.BatchNorm2d(64)\n",
    "        self.conv3 = M.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = M.ReLU()\n",
    "        self.bn3 = M.BatchNorm2d(64)\n",
    "        self.conv4 = M.Conv2d(64, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu4 = M.ReLU()\n",
    "        self.fc = M.Linear(10368, 81*9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = F.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = F.reshape(x, (-1, 81, 9))\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(\"model initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.准备训练数据，设置优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "padding_size = 3\n",
    "\n",
    "def get_data(file): \n",
    "    data = pd.read_csv(file)\n",
    "    feat_raw = data['quizzes']\n",
    "    label_raw = data['solutions']\n",
    "    feat = []\n",
    "    label = []\n",
    "\n",
    "#     for i in feat_raw:\n",
    "#         x = np.array([int(j) for j in i]).reshape((1,9,9))\n",
    "#         feat.append(x)\n",
    "#     feat = np.array(feat)\n",
    "#     feat = feat/9\n",
    "#     feat -= .5 \n",
    "#     for i in label_raw:\n",
    "#         x = np.array([int(j) for j in i]).reshape((1,81)) - 1\n",
    "#         label.append(x)\n",
    "#     label = np.array(label)\n",
    "    \n",
    "    s = set()\n",
    "    t = 0\n",
    "    for i in range(len(feat_raw)):\n",
    "        x = feat_raw[i]\n",
    "        y = label_raw[i]\n",
    "        z = np.array([int(j) for j in y]).reshape((1, 81)) - 1\n",
    "        if x not in s:\n",
    "            s.add(x)\n",
    "            a = np.array([int(j) for j in x]).reshape((1, 9, 9))\n",
    "            feat.append(a)\n",
    "            b = [z for j in range(padding_size)]\n",
    "            label.append(b)\n",
    "            t = 1\n",
    "        else:\n",
    "            label[-1][t] = z\n",
    "            t += 1\n",
    "    feat = np.array(feat)\n",
    "    feat = feat/9\n",
    "    feat -= .5\n",
    "    label = np.array(label)\n",
    "    \n",
    "    del(feat_raw)\n",
    "    del(label_raw)    \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feat, label, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_data('data/sudoku_extended.csv')\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,x_train,y_train):\n",
    "        super().__init__()\n",
    "        self.data_x = x_train\n",
    "        self.data_y = y_train\n",
    "    def __getitem__(self, index:int) -> Tuple:\n",
    "        return self.data_x[index], self.data_y[index]\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_x)\n",
    "\n",
    "train_dataset = TrainDataset(x_train, y_train)\n",
    "train_sampler = RandomSampler(dataset = train_dataset, batch_size=32)\n",
    "train_dataloader = DataLoader(dataset = train_dataset, sampler=train_sampler)\n",
    "\n",
    "opt = Adam(model.parameters(), lr = 1e-3)\n",
    "print(\"Data Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0:training process:   0%|          | 0/250.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0:training process: 100%|██████████| 250/250.0 [1:03:21<00:00, 15.21s/it, loss=10.92054]\n",
      "epoch 1:training process: 100%|██████████| 250/250.0 [1:03:19<00:00, 15.20s/it, loss=10.82663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"start training\")\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    iter = 0\n",
    "    with tqdm(total=train_dataloader.__len__() / 100, desc=\"epoch {}:training process\".format(epoch)) as tq:\n",
    "        for i, (feat, label) in enumerate(train_dataloader):\n",
    "            gm = GradManager().attach(model.parameters())\n",
    "            with gm:\n",
    "                logits = model(tensor(feat))\n",
    "                label = label.reshape(32, padding_size, 81)\n",
    "                loss = tensor(0)\n",
    "                for j in range(32):\n",
    "                    l = tensor(F.ones(padding_size))\n",
    "                    for k in range(padding_size):\n",
    "                        l[k] = F.loss.cross_entropy(logits[j], label[j][k], axis=1)\n",
    "                    loss += l.min()\n",
    "                \n",
    "                iter += 1\n",
    "                if iter % 100 == 0:\n",
    "                    tq.set_postfix({\"loss\": \"{0:1.5f}\".format(loss.numpy().item()),})\n",
    "                    tq.update(1)\n",
    "                    \n",
    "                gm.backward(loss)\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "mge.save(model, \"1.mge\")\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.模型评估\n",
    "\n",
    "你需要修改这部分的代码，以完成作业Q1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating process:   0%|          | 0/62.5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating process:  99%|█████████▉| 62/62.5 [10:35<00:05, 10.24s/it, loss=0.31998]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33382902927398683\n",
      "Tensor(0.8442119, device=xpux:0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model = mge.load(\"1.mge\")\n",
    "model.eval()\n",
    "\n",
    "eval_dataset = TrainDataset(x_test, y_test)\n",
    "eval_sampler = RandomSampler(dataset = eval_dataset, batch_size=32)\n",
    "eval_dataloader = DataLoader(dataset = eval_dataset, sampler=eval_sampler)\n",
    "\n",
    "print(\"start evaluating\")\n",
    "average_loss = 0\n",
    "average_acc = 0.\n",
    "iter = 0\n",
    "with tqdm(total=eval_dataloader.__len__() / 100, desc=\"evaluating process\") as tq:\n",
    "    for i, (feat, label) in enumerate(eval_dataloader):\n",
    "            logits = model(tensor(feat))\n",
    "            label = label.reshape(32, padding_size, 81)\n",
    "            loss = tensor(0)\n",
    "            for j in range(32):\n",
    "                l = tensor(F.ones(padding_size))\n",
    "                r = []\n",
    "                for k in range(padding_size):\n",
    "                    l[k] = F.loss.cross_entropy(logits[j], label[j][k], axis=1)\n",
    "                    a = F.softmax(logits[j])\n",
    "                    a = a.reshape(81, 9)\n",
    "                    pred = F.argmax(a, axis=1).reshape((81))\n",
    "                    correct = F.sum(F.equal(pred, tensor(label[j][k])))\n",
    "                    r.append(correct / 81)\n",
    "                loss += l.min()\n",
    "                average_acc += max(r)/32\n",
    "            \n",
    "            iter += 1\n",
    "            if iter % 100 == 0:\n",
    "                tq.set_postfix({\"loss\": \"{0:1.5f}\".format(loss.numpy().item()/32),})\n",
    "                tq.update(1)\n",
    "            average_loss += loss.numpy().item()/32\n",
    "\n",
    "print(average_loss / eval_dataloader.__len__())\n",
    "print(average_acc / eval_dataloader.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.输入一个你自己的数独游戏，并查看模型的输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solved puzzle:\n",
      "\n",
      "[[4 8 9 5 3 2 7 6 1]\n",
      " [7 1 3 4 8 6 5 9 2]\n",
      " [5 6 2 9 1 7 8 3 4]\n",
      " [2 5 8 3 4 1 9 7 6]\n",
      " [6 3 1 7 5 9 2 4 8]\n",
      " [9 4 7 2 6 8 1 5 3]\n",
      " [1 2 5 6 7 3 4 8 9]\n",
      " [8 7 6 1 9 4 3 2 5]\n",
      " [3 9 4 8 2 5 6 1 7]]\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "model = mge.load(\"1.mge\")\n",
    "model.eval()\n",
    "\n",
    "def norm(x):\n",
    "    return (x/9)-.5\n",
    "\n",
    "def denorm(x):\n",
    "    return (x+.5)*9\n",
    "\n",
    "def inference_sudoku(sample):\n",
    "    feat = copy.copy(sample)\n",
    "    \n",
    "    while(1):\n",
    "        out = F.softmax(model(tensor(feat.reshape((1, 1, 9, 9)))), axis= 2)\n",
    "        out = out.reshape(81, 9)\n",
    "\n",
    "        pred = F.argmax(out, axis=1).reshape((9, 9))+1 \n",
    "        prob = np.around(F.max(out, axis=1).reshape((9, 9)), 2) \n",
    "        feat = denorm(feat).reshape((9, 9))\n",
    "        mask = ( feat == 0 )\n",
    "        if mask.sum() == 0:\n",
    "            break\n",
    "            \n",
    "        prob_new = prob * mask \n",
    "        ind = F.argmax(prob_new) \n",
    "        x, y = (ind // 9), (ind % 9)\n",
    "        \n",
    "        val = pred[x][y].numpy()\n",
    "        feat[x][y] = int(val)\n",
    "        feat = norm(feat)\n",
    "    \n",
    "    return feat\n",
    "\n",
    "def solve_sudoku(game):\n",
    "    \n",
    "    game = game.replace('\\n', '')\n",
    "    game = game.replace(' ', '')\n",
    "    game = np.array([int(j) for j in game]).reshape((9,9,1))\n",
    "    game = norm(game)\n",
    "    game = inference_sudoku(game)\n",
    "    return game\n",
    "\n",
    "game = '''\n",
    "          0 8 0 0 3 2 0 0 1\n",
    "          7 0 3 0 8 0 0 0 2\n",
    "          5 0 0 0 0 7 0 3 0\n",
    "          0 5 0 0 0 1 9 7 0\n",
    "          6 0 0 7 0 9 0 0 8\n",
    "          0 4 7 2 0 0 0 5 0\n",
    "          0 2 0 6 0 0 0 0 9\n",
    "          8 0 0 0 9 0 3 0 5\n",
    "          3 0 0 8 2 0 0 1 0\n",
    "      '''\n",
    "\n",
    "game = solve_sudoku(game)\n",
    "\n",
    "print('solved puzzle:\\n')\n",
    "print(game.astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果展示\n",
    "\n",
    "展示为baseline效果。\n",
    "\n",
    "![sudoku.png](https://data.megengine.org.cn/megstudio/images/sudoku.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
